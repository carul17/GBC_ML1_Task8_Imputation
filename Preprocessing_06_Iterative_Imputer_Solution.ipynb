{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IterativeImputer\n",
    "### This notebook outlines the usage of Iterative Imputer (Multivariate Imputation).\n",
    "### Iterative Imputer substitutes missing values as a function of other features\n",
    "#### Dataset: [https://github.com/subashgandyer/datasets/blob/main/heart_disease.csv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demographic**\n",
    "- Sex: male or female(Nominal)\n",
    "- Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
    "\n",
    "**Behavioral**\n",
    "- Current Smoker: whether or not the patient is a current smoker (Nominal)\n",
    "- Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
    "\n",
    "**Medical(history)**\n",
    "- BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
    "- Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
    "- Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
    "- Diabetes: whether or not the patient had diabetes (Nominal)\n",
    "\n",
    "**Medical(current)**\n",
    "- Tot Chol: total cholesterol level (Continuous)\n",
    "- Sys BP: systolic blood pressure (Continuous)\n",
    "- Dia BP: diastolic blood pressure (Continuous)\n",
    "- BMI: Body Mass Index (Continuous)\n",
    "- Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n",
    "- Glucose: glucose level (Continuous)\n",
    "\n",
    "**Predict variable (desired target)**\n",
    "- 10 year risk of coronary heart disease CHD (binary: “1”, means “Yes”, “0” means “No”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many Categorical variables in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many Missing values in the dataset?\n",
    "Hint: df.Series.isna( ).sum( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.columns)):\n",
    "    missing_data = df[df.columns[i]].isna().sum()\n",
    "    perc = missing_data / len(df) * 100\n",
    "    print(f'Feature {i+1} >> Missing entries: {missing_data}  |  Percentage: {round(perc, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Visual representation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isna(), cbar=False, cmap='viridis', yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IterativeImputer object with max_iterations and random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - converting df into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :-1]\n",
    "y = data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the imputer model on dataset to perform iterative multivariate imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained imputer model is applied to dataset to create a copy of dataset with all filled missing values using transform( ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check: Whether missing values are filled or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing cells: {sum(np.isnan(X).flatten())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing cells: {sum(np.isnan(X_transform).flatten())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to visualize the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isna(), cbar=False, cmap='viridis', yticklabels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(X_transform.isna(), cbar=False, cmap='viridis', yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the issue here?\n",
    "#### Hint: Heatmap needs a DataFrame and not a Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform = pd.DataFrame(data=X_transform)\n",
    "df_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df_transform.isna(), cbar=False, cmap='viridis', yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if these datasets contain missing data\n",
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "Y_train = pd.read_csv(\"Y_train.csv\")\n",
    "Y_test = pd.read_csv(\"Y_test.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(X_train.isna(), cbar=False, cmap='viridis', yticklabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there missing data in this dataset???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in X_train\n",
    "missing_counts = X_train.isna().sum()\n",
    "total_missing = missing_counts.sum()\n",
    "\n",
    "print(f\"Total missing values: {total_missing}\")\n",
    "print(\"\\nMissing values by column:\")\n",
    "for col, count in missing_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count} missing values\")\n",
    "        \n",
    "if total_missing == 0:\n",
    "    print(\"\\nNo missing values found in the training dataset. This is also confirmed by the graph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Logistic Regression model Without imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop all rows with missing entries - Build a Logistic Regression model and benchmark the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[df.columns[-1]]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline with model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RepeatedStratifiedKFold with 10 splits and 3 repeats and random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call cross_val_score with pipeline, X, y, accuracy metric and cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_from_dropna = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_from_dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the Mean Accuracy and Standard Deviation from scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Accuracy: {round(np.mean(scores_from_dropna), 3)}  | Std: {round(np.std(scores_from_dropna), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Logistic Regression model with IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"heart_disease.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[df.columns[-1]]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SimpleImputer with mean strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline with impute and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('impute', imputer), ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RepeatedStratifiedKFold with 10 splits and 3 repeats and random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call cross_val_score with pipeline, X, y, accuracy metric and cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_from_imputer = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_from_imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the Mean Accuracy and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Accuracy: {round(np.mean(scores_from_imputer), 3)}  | Std: {round(np.std(scores_from_imputer), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which accuracy is better? \n",
    "- Dropping missing values\n",
    "- SimpleImputer with Mean Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of Strategies:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"1. Dropping missing values:\")\n",
    "print(f\"Mean Accuracy: {round(np.mean(scores_from_dropna), 3)}  | Std: {round(np.std(scores_from_dropna), 3)}\")\n",
    "print(\"\\n2. SimpleImputer with Mean Strategy:\")\n",
    "print(f\"Mean Accuracy: {round(np.mean(scores_from_imputer), 3)}  | Std: {round(np.std(scores_from_imputer), 3)}\")\n",
    "print(\"\\nConclusion: SimpleImputer with Mean Strategy performs slightly better\")\n",
    "print(\"and preserves more data compared to dropping rows with missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IterativeImputer with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('impute', imputer), ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Accuracy: {round(np.mean(scores), 3)}  | Std: {round(np.std(scores), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiments with different Imputation methods and different algorithms\n",
    "\n",
    "## Imputation Methods\n",
    "- Mean\n",
    "- Median\n",
    "- Most_frequent\n",
    "- Constant\n",
    "- IterativeImputer\n",
    "\n",
    "## ALGORITHMS\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- Random Forest\n",
    "- SVM\n",
    "- Any other algorithm of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of all combinations:\n",
      "--------------------------------------------------------------------------------\n",
      "Strategy: SimpleImputer (most_frequent) Model: Logistic Regression  Accuracy: 0.855 ± 0.006\n",
      "Strategy: SimpleImputer (median)    Model: Logistic Regression  Accuracy: 0.855 ± 0.006\n",
      "Strategy: IterativeImputer          Model: Logistic Regression  Accuracy: 0.855 ± 0.006\n",
      "Strategy: SimpleImputer (mean)      Model: Logistic Regression  Accuracy: 0.855 ± 0.005\n",
      "Strategy: SimpleImputer (constant)  Model: Logistic Regression  Accuracy: 0.854 ± 0.005\n",
      "Strategy: SimpleImputer (mean)      Model: Random Forest        Accuracy: 0.850 ± 0.006\n",
      "Strategy: SimpleImputer (median)    Model: Random Forest        Accuracy: 0.850 ± 0.006\n",
      "Strategy: SimpleImputer (most_frequent) Model: Random Forest        Accuracy: 0.849 ± 0.006\n",
      "Strategy: IterativeImputer          Model: Random Forest        Accuracy: 0.849 ± 0.006\n",
      "Strategy: SimpleImputer (median)    Model: SVM                  Accuracy: 0.848 ± 0.002\n",
      "Strategy: SimpleImputer (most_frequent) Model: SVM                  Accuracy: 0.848 ± 0.002\n",
      "Strategy: SimpleImputer (mean)      Model: SVM                  Accuracy: 0.848 ± 0.002\n",
      "Strategy: IterativeImputer          Model: SVM                  Accuracy: 0.848 ± 0.002\n",
      "Strategy: SimpleImputer (constant)  Model: SVM                  Accuracy: 0.848 ± 0.002\n",
      "Strategy: SimpleImputer (constant)  Model: Random Forest        Accuracy: 0.848 ± 0.006\n",
      "Strategy: SimpleImputer (constant)  Model: KNN                  Accuracy: 0.837 ± 0.010\n",
      "Strategy: SimpleImputer (mean)      Model: KNN                  Accuracy: 0.837 ± 0.009\n",
      "Strategy: IterativeImputer          Model: KNN                  Accuracy: 0.837 ± 0.008\n",
      "Strategy: SimpleImputer (median)    Model: KNN                  Accuracy: 0.836 ± 0.008\n",
      "Strategy: SimpleImputer (most_frequent) Model: KNN                  Accuracy: 0.835 ± 0.009\n",
      "\n",
      "Best combination:\n",
      "Strategy: SimpleImputer (most_frequent)\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.855 ± 0.006\n"
     ]
    }
   ],
   "source": [
    "# Import required models and imputers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "# Define imputation strategies and models to test\n",
    "simple_imputer_strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=10000)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=1)),\n",
    "    ('SVM', SVC(random_state=1))\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Create cross-validation object\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Test SimpleImputer strategies\n",
    "for strategy in simple_imputer_strategies:\n",
    "    for model_name, model in models:\n",
    "        # Create pipeline with SimpleImputer\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=strategy)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Evaluate model\n",
    "        scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'strategy': f'SimpleImputer ({strategy})',\n",
    "            'model': model_name,\n",
    "            'mean_accuracy': np.mean(scores),\n",
    "            'std': np.std(scores)\n",
    "        })\n",
    "\n",
    "# Test IterativeImputer\n",
    "for model_name, model in models:\n",
    "    # Create pipeline with IterativeImputer\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', IterativeImputer(max_iter=10, random_state=0)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Evaluate model\n",
    "    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'strategy': 'IterativeImputer',\n",
    "        'model': model_name,\n",
    "        'mean_accuracy': np.mean(scores),\n",
    "        'std': np.std(scores)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by mean accuracy in descending order\n",
    "results_df = results_df.sort_values('mean_accuracy', ascending=False)\n",
    "\n",
    "# Display results in a formatted table\n",
    "print(\"Results of all combinations:\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in results_df.iterrows():\n",
    "    print(f\"Strategy: {row['strategy']:<25} Model: {row['model']:<20} \"\n",
    "          f\"Accuracy: {row['mean_accuracy']:.3f} ± {row['std']:.3f}\")\n",
    "\n",
    "# Display the best combination\n",
    "best_result = results_df.iloc[0]\n",
    "print(\"\\nBest combination:\")\n",
    "print(f\"Strategy: {best_result['strategy']}\")\n",
    "print(f\"Model: {best_result['model']}\")\n",
    "print(f\"Accuracy: {best_result['mean_accuracy']:.3f} ± {best_result['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Which is the best strategy for this dataset using Random Forest algorithm?\n",
    "- SimpleImputer(Mean)\n",
    "- SimpleImputer(Median)\n",
    "- SimpleImputer(Most_frequent)\n",
    "- SimpleImputer(Constant)\n",
    "- IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest performance with different strategies:\n",
      "--------------------------------------------------\n",
      "Strategy: SimpleImputer (mean) Accuracy: 0.850 ± 0.006\n",
      "Strategy: SimpleImputer (median) Accuracy: 0.850 ± 0.006\n",
      "Strategy: SimpleImputer (most_frequent) Accuracy: 0.849 ± 0.006\n",
      "Strategy: IterativeImputer Accuracy: 0.849 ± 0.006\n",
      "Strategy: SimpleImputer (constant) Accuracy: 0.848 ± 0.006\n",
      "\n",
      "Best strategy for Random Forest: SimpleImputer (mean) with accuracy 0.850 ± 0.006\n"
     ]
    }
   ],
   "source": [
    "# Filter results for Random Forest\n",
    "rf_results = results_df[results_df['model'] == 'Random Forest']\n",
    "print(\"Random Forest performance with different strategies:\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in rf_results.iterrows():\n",
    "    print(f\"Strategy: {row['strategy']:<15} Accuracy: {row['mean_accuracy']:.3f} ± {row['std']:.3f}\")\n",
    "    \n",
    "best_rf = rf_results.loc[rf_results['mean_accuracy'].idxmax()]\n",
    "print(f\"\\nBest strategy for Random Forest: {best_rf['strategy']} with accuracy {best_rf['mean_accuracy']:.3f} ± {best_rf['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2:  Which is the best algorithm for this dataset using IterativeImputer?\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- KNN\n",
    "- any other algorithm of your choice (BONUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterative imputer strategy performance with different algorithms:\n",
      "--------------------------------------------------\n",
      "Algorithm: Logistic Regression  Accuracy: 0.855 ± 0.006\n",
      "Algorithm: Random Forest        Accuracy: 0.849 ± 0.006\n",
      "Algorithm: SVM                  Accuracy: 0.848 ± 0.002\n",
      "Algorithm: KNN                  Accuracy: 0.837 ± 0.008\n",
      "\n",
      "Best algorithm with Iterative Imputer strategy: Logistic Regression with accuracy 0.855 ± 0.006\n"
     ]
    }
   ],
   "source": [
    "# Filter results for Iterative Imputer strategy\n",
    "mean_results = results_df[results_df['strategy'] == 'IterativeImputer']\n",
    "print(\"Iterative imputer strategy performance with different algorithms:\")\n",
    "print(\"-\" * 50)\n",
    "for _, row in mean_results.iterrows():\n",
    "    print(f\"Algorithm: {row['model']:<20} Accuracy: {row['mean_accuracy']:.3f} ± {row['std']:.3f}\")\n",
    "    \n",
    "best_mean = mean_results.loc[mean_results['mean_accuracy'].idxmax()]\n",
    "print(f\"\\nBest algorithm with Iterative Imputer strategy: {best_mean['model']} with accuracy {best_mean['mean_accuracy']:.3f} ± {best_mean['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: Which is the best combination of algorithm and best Imputation Strategy overall?\n",
    "- Mean , Median, Most_frequent, Constant, IterativeImputer\n",
    "- Logistic Regression, Random Forest, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall combination:\n",
      "--------------------------------------------------\n",
      "Strategy: SimpleImputer (most_frequent)\n",
      "Algorithm: Logistic Regression\n",
      "Accuracy: 0.855 ± 0.006\n"
     ]
    }
   ],
   "source": [
    "# Find best overall combination\n",
    "best_overall = results_df.loc[results_df['mean_accuracy'].idxmax()]\n",
    "print(\"Best overall combination:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Strategy: {best_overall['strategy']}\")\n",
    "print(f\"Algorithm: {best_overall['model']}\")\n",
    "print(f\"Accuracy: {best_overall['mean_accuracy']:.3f} ± {best_overall['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Summary\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **Best Random Forest Strategy (Q1)**:\n",
    "   - SimpleImputer with Mean strategy performed best (0.850 ± 0.006)\n",
    "   - Tied with Median strategy (0.850 ± 0.006)\n",
    "   - Other strategies performed slightly worse but with minimal difference\n",
    "\n",
    "2. **Best Algorithm with IterativeImputer (Q2)**:\n",
    "   - Logistic Regression clearly outperformed others (0.855 ± 0.006)\n",
    "   - Significant gap to next best: Random Forest (0.849 ± 0.006)\n",
    "   - KNN performed worst (0.837 ± 0.008)\n",
    "\n",
    "3. **Best Overall Combination (Q3)**:\n",
    "   - Logistic Regression with SimpleImputer(most_frequent) (0.855 ± 0.006)\n",
    "   - Equally good performance with median imputation and IterativeImputer\n",
    "   - Most_frequent strategy might be preferred for simplicity\n",
    "\n",
    "## Observations\n",
    "\n",
    "- Logistic Regression consistently performed well across different imputation strategies\n",
    "- The choice of imputation strategy had relatively small impact on model performance\n",
    "- Simpler imputation methods (mean, median, most_frequent) performed as well as or better than the more complex IterativeImputer\n",
    "- Standard deviations were consistently low, indicating stable model performance\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "1. Use Logistic Regression as the primary model for this dataset\n",
    "2. Choose SimpleImputer with most_frequent strategy for simplicity and performance\n",
    "3. Consider computational cost vs. performance when choosing between simple imputation and IterativeImputer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
